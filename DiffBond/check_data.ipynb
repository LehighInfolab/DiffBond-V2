{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176201a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured:\n",
      "  SKEMPI_CSV: ../../SKEMPI_dataset_download/skempi_v2.csv\n",
      "  BASE_PATHS: ['../../MT_Processing_Archive/base-0', '../../MT_Processing_Archive/base-1', '../../MT_Processing_Archive/base-2', '../../MT_Processing_Archive/base-3', '../../MT_Processing_Archive/base-4', '../../MT_Processing_Archive/base-5', '../../MT_Processing_Archive/base-6', '../../MT_Processing_Archive/base-7']\n",
      "  OUTPUT_ROOT: results\n",
      "  EXPECTED_FILE: None\n",
      "  START_FROM: None\n",
      "  CSV_DIR: /Users/justintam/Lehigh University Dropbox/Justin Tam/Research Resources/2024_DiffBondv3/DiffBond\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to your SKEMPI CSV used by parse_skempi()\n",
    "SKEMPI_CSV = Path(\"../../SKEMPI_dataset_download/skempi_v2.csv\")\n",
    "\n",
    "# One or more base-* input directories that you already processed.\n",
    "# Example: [\"../../MT_Processing_Archive/base-7\"]\n",
    "BASE_PATHS = [\n",
    "    \"../../MT_Processing_Archive/base-0\",\n",
    "    \"../../MT_Processing_Archive/base-1\",\n",
    "    \"../../MT_Processing_Archive/base-2\",\n",
    "    \"../../MT_Processing_Archive/base-3\",\n",
    "    \"../../MT_Processing_Archive/base-4\",\n",
    "    \"../../MT_Processing_Archive/base-5\",\n",
    "    \"../../MT_Processing_Archive/base-6\",\n",
    "]\n",
    "\n",
    "# Wildtype input directories (each contains many PDB folders with H*-* halves)\n",
    "# Adjust to where your WT inputs actually are.\n",
    "WT_PATHS = [\n",
    "    \"../../SKEMPI_dataset_download/wt\",\n",
    "]\n",
    "\n",
    "# Where DiffBond actually wrote outputs (choose one): \"results\" or \"Results\"\n",
    "OUTPUT_ROOT = \"results\"\n",
    "\n",
    "# If you want to check for a *specific* file inside each output dir, set it here.\n",
    "# e.g., EXPECTED_FILE = \"combined_edges.parquet\" or None to accept any non-empty dir.\n",
    "EXPECTED_FILE = None  # e.g., \"combined_edges.parquet\"\n",
    "\n",
    "# If you only want to audit starting at a certain folder number, set START_FROM\n",
    "# to a string like \"00325\" or an int like 325. Or leave as None to audit all.\n",
    "START_FROM = None\n",
    "\n",
    "# CSV outputs will be written next to this script/notebook.\n",
    "CSV_DIR = Path(\"./\")\n",
    "CSV_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configured:\")\n",
    "print(\"  SKEMPI_CSV:\", SKEMPI_CSV)\n",
    "print(\"  BASE_PATHS:\", BASE_PATHS)\n",
    "print(\"  WT_PATHS:\", WT_PATHS)\n",
    "print(\"  OUTPUT_ROOT:\", OUTPUT_ROOT)\n",
    "print(\"  EXPECTED_FILE:\", EXPECTED_FILE)\n",
    "print(\"  START_FROM:\", START_FROM)\n",
    "print(\"  CSV_DIR:\", CSV_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fb18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_pdb_dict size: 7085\n",
      "sample: [('00001', 'base-0/1CSE/00001'), ('00002', 'base-0/1CSE/00002'), ('00003', 'base-0/1CSE/00003')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def rebuild_idx_pdb_dict(skempi_csv: Path):\n",
    "    \"\"\"\n",
    "    Mirrors parse_skempi():\n",
    "      - Skip header row\n",
    "      - base_idx starts at 0\n",
    "      - base_idx increments when (index % 1000 == 0)\n",
    "      - formatted_index = f\"{index:05d}\"\n",
    "      - mapping: formatted_index -> \"base-{base_idx}/{pdb}/{formatted_index}\"\n",
    "    \"\"\"\n",
    "    idx_pdb_dict = {}\n",
    "    base_idx = 0\n",
    "    with open(skempi_csv, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\";\")\n",
    "        for index, row in enumerate(reader):\n",
    "            if index == 0:\n",
    "                continue  # header\n",
    "            pdb = row[0].split(\"_\")[0]\n",
    "            if index % 1000 == 0:\n",
    "                base_idx += 1\n",
    "            formatted_index = f\"{index:05d}\"\n",
    "            idx_pdb_dict[formatted_index] = f\"base-{base_idx}/{pdb}/{formatted_index}\"\n",
    "    return idx_pdb_dict\n",
    "\n",
    "idx_pdb_dict = rebuild_idx_pdb_dict(SKIEMPI_CSV)\n",
    "print(\"idx_pdb_dict size:\", len(idx_pdb_dict))\n",
    "print(\"sample:\", list(idx_pdb_dict.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025894bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "def _ordered_folders(path: str, start_from: Optional[object] = None) -> List[str]:\n",
    "    try:\n",
    "        entries = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    except OSError as e:\n",
    "        print(f\"[ERROR] Could not list directory '{path}': {e}\")\n",
    "        return []\n",
    "    numeric = sorted([d for d in entries if d.isdigit()], key=lambda s: int(s))\n",
    "    non_numeric = [d for d in entries if not d.isdigit()]\n",
    "    if start_from is None:\n",
    "        return numeric + non_numeric\n",
    "    s = str(start_from)\n",
    "    if s.isdigit():\n",
    "        start_int = int(s)\n",
    "        numeric = [d for d in numeric if int(d) >= start_int]\n",
    "        return numeric + non_numeric\n",
    "    else:\n",
    "        ordered = numeric + non_numeric\n",
    "        if s in ordered:\n",
    "            return ordered[ordered.index(s):]\n",
    "        print(f\"[WARN] start_from '{s}' not found; processing all.\")\n",
    "        return ordered\n",
    "\n",
    "def _dir_nonempty(p: Path) -> bool:\n",
    "    try:\n",
    "        return p.exists() and any(p.iterdir())\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def write_missing_csv(rows: List[Tuple[str, str]], csv_path: Path) -> None:\n",
    "    import csv\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"input_id\", \"expected_output_dir\"])\n",
    "        w.writerows(rows)\n",
    "    print(f\"[INFO] Wrote CSV: {csv_path} ({len(rows)} rows)\")\n",
    "\n",
    "\n",
    "# === ðŸ§ª Audit mutants (base-*) ===\n",
    "def audit_base_path(\n",
    "    base_path: str,\n",
    "    idx_pdb_dict: Dict[str, str],\n",
    "    output_root: str = \"results\",\n",
    "    expected_file: Optional[str] = None,\n",
    "    start_from: Optional[object] = None,\n",
    ") -> Tuple[int, int, List[Tuple[str, str]]]:\n",
    "    folders = _ordered_folders(base_path, start_from)\n",
    "    total_inputs = sum(1 for f in folders if str(f).isdigit())\n",
    "    success = 0\n",
    "    missing: List[Tuple[str, str]] = []\n",
    "\n",
    "    for folder in folders:\n",
    "        if not str(folder).isdigit():\n",
    "            continue\n",
    "        if folder not in idx_pdb_dict:\n",
    "            # Can't infer output path; record as missing mapping\n",
    "            missing.append((folder, \"<no mapping in idx_pdb_dict>\"))\n",
    "            continue\n",
    "        rel = idx_pdb_dict[folder]  # e.g., base-3/1ABC/00042\n",
    "        out_dir = Path(output_root) / rel\n",
    "        if expected_file:\n",
    "            ok = (out_dir / expected_file).is_file()\n",
    "        else:\n",
    "            ok = _dir_nonempty(out_dir)\n",
    "        if ok:\n",
    "            success += 1\n",
    "        else:\n",
    "            missing.append((folder, str(out_dir)))\n",
    "\n",
    "    return total_inputs, success, missing\n",
    "\n",
    "\n",
    "# === ðŸ§ª Audit wildtypes ===\n",
    "def audit_wt_path(\n",
    "    wt_root: str,\n",
    "    output_root: str = \"results\",\n",
    "    expected_file: Optional[str] = None,\n",
    ") -> Tuple[int, int, List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    WT outputs are written as OUTPUT_ROOT / \"wt\" / <PDB>\n",
    "    Count a PDB as success if that directory exists and is non-empty\n",
    "    (or contains EXPECTED_FILE if provided).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdb_dirs = [d for d in os.listdir(wt_root) if os.path.isdir(os.path.join(wt_root, d))]\n",
    "    except OSError as e:\n",
    "        print(f\"[ERROR] Could not list WT root '{wt_root}': {e}\")\n",
    "        return 0, 0, []\n",
    "\n",
    "    # Filter to plausible PDB folder names (alnum, usually length 4; keep permissive)\n",
    "    pdbs = [d for d in pdb_dirs if len(d) >= 4]  # adjust if needed\n",
    "\n",
    "    total_inputs = len(pdbs)\n",
    "    success = 0\n",
    "    missing: List[Tuple[str, str]] = []\n",
    "\n",
    "    for pdb in sorted(pdbs):\n",
    "        out_dir = Path(output_root) / \"wt\" / pdb\n",
    "        if expected_file:\n",
    "            ok = (out_dir / expected_file).is_file()\n",
    "        else:\n",
    "            ok = _dir_nonempty(out_dir)\n",
    "        if ok:\n",
    "            success += 1\n",
    "        else:\n",
    "            missing.append((pdb, str(out_dir)))\n",
    "\n",
    "    return total_inputs, success, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d773bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-0 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-0': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-0'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-0.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-1 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-1': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-1'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-1.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-2 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-2': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-2'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-2.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-3 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-3': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-3'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-3.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-4 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-4': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-4'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-4.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-5 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-5': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-5'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-5.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-6 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-6': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-6'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-6.csv (0 rows)\n",
      "\n",
      "=== Auditing: ../../MT_Processing_Archive/base-7 ===\n",
      "[ERROR] Could not list directory '../../MT_Processing_Archive/base-7': [Errno 2] No such file or directory: '../../MT_Processing_Archive/base-7'\n",
      "inputs=0 | success=0 | failed=0 | success_rate=0.00%\n",
      "[INFO] Wrote missing CSV: audit_missing_base-7.csv (0 rows)\n",
      "\n",
      "=== Summary ===\n",
      "../../MT_Processing_Archive/base-0: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-1: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-2: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-3: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-4: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-5: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-6: inputs=0, success=0, failed=0, success_rate=0.00%\n",
      "../../MT_Processing_Archive/base-7: inputs=0, success=0, failed=0, success_rate=0.00%\n"
     ]
    }
   ],
   "source": [
    "# === â–¶ï¸ Run: mutants ===\n",
    "mutant_summary = []\n",
    "for base_path in BASE_PATHS:\n",
    "    print(f\"\\n=== Auditing mutants: {base_path} ===\")\n",
    "    total, success, missing = audit_base_path(\n",
    "        base_path=base_path,\n",
    "        idx_pdb_dict=idx_pdb_dict,\n",
    "        output_root=OUTPUT_ROOT,\n",
    "        expected_file=EXPECTED_FILE,\n",
    "        start_from=START_FROM,\n",
    "    )\n",
    "    failed = total - success\n",
    "    rate = (success / total * 100.0) if total else 0.0\n",
    "    print(f\"inputs={total} | success={success} | failed={failed} | success_rate={rate:.2f}%\")\n",
    "\n",
    "    csv_path = CSV_DIR / f\"audit_missing_{Path(base_path).name}.csv\"\n",
    "    write_missing_csv(missing, csv_path)\n",
    "    mutant_summary.append((base_path, total, success, failed, rate))\n",
    "\n",
    "print(\"\\n=== Mutant Summary ===\")\n",
    "for base_path, total, success, failed, rate in mutant_summary:\n",
    "    print(f\"{base_path}: inputs={total}, success={success}, failed={failed}, success_rate={rate:.2f}%\")\n",
    "\n",
    "\n",
    "# === â–¶ï¸ Run: wildtypes ===\n",
    "wt_summary = []\n",
    "all_wt_missing: List[Tuple[str, str]] = []\n",
    "for wt_path in WT_PATHS:\n",
    "    print(f\"\\n=== Auditing wildtypes: {wt_path} ===\")\n",
    "    total, success, missing = audit_wt_path(\n",
    "        wt_root=wt_path,\n",
    "        output_root=OUTPUT_ROOT,\n",
    "        expected_file=EXPECTED_FILE,\n",
    "    )\n",
    "    failed = total - success\n",
    "    rate = (success / total * 100.0) if total else 0.0\n",
    "    print(f\"WT inputs={total} | success={success} | failed={failed} | success_rate={rate:.2f}%\")\n",
    "\n",
    "    csv_path = CSV_DIR / f\"audit_missing_wt_{Path(wt_path).name}.csv\"\n",
    "    write_missing_csv(missing, csv_path)\n",
    "    wt_summary.append((wt_path, total, success, failed, rate))\n",
    "    all_wt_missing.extend(missing)\n",
    "\n",
    "print(\"\\n=== WT Summary ===\")\n",
    "for wt_path, total, success, failed, rate in wt_summary:\n",
    "    print(f\"{wt_path}: inputs={total}, success={success}, failed={failed}, success_rate={rate:.2f}%\")\n",
    "\n",
    "# Optional: combined WT CSV\n",
    "if len(WT_PATHS) > 1:\n",
    "    combined_csv = CSV_DIR / \"audit_missing_wt_all.csv\"\n",
    "    write_missing_csv(all_wt_missing, combined_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BondNetwork",
   "language": "python",
   "name": "bondnetwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
